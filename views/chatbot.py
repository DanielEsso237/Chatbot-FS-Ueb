import os
import streamlit as st
import time
from dotenv import load_dotenv
from backend.chatbot_logic import OptimizedChatbotLogic

load_dotenv()

def load_custom_css():
    css_file = "assets/styles/chatbot.css"
    if os.path.exists(css_file):
        with open(css_file, "r", encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

class OptimizedChatbotUI:
    def __init__(self, pdf_folder):
        self.chatbot_logic = OptimizedChatbotLogic(pdf_folder)
        if "model_preloaded" not in st.session_state:
            with st.spinner("ğŸ”§ Initialisation du modÃ¨le..."):
                self.chatbot_logic.preload_model()
            st.session_state.model_preloaded = True

    def get_base64_image(self, image_path):
        try:
            import base64
            with open(image_path, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode()
        except:
            return ""

    def render_header(self):
        logo_path = "assets/images/logo.png"
        header_html = f"""
        <div class="custom-header fade-in">
            <h1>
                {'<img src="data:image/png;base64,' + self.get_base64_image(logo_path) + '" class="logo-header"/>' if os.path.exists(logo_path) else 'ğŸ“'}
                Chatbot FS-UEb âš¡
            </h1>
            <p>Assistant Intelligent OptimisÃ© - FacultÃ© des Sciences, UniversitÃ© d'Ebolowa</p>
        </div>
        """
        st.markdown(header_html, unsafe_allow_html=True)

    def render_sidebar(self):
        with st.sidebar:
            logo_path = "assets/images/logo.png"
            if os.path.exists(logo_path):
                st.markdown(f'<img src="data:image/png;base64,{self.get_base64_image(logo_path)}" class="sidebar-logo"/>', unsafe_allow_html=True)
            else:
                st.markdown("ğŸ“", unsafe_allow_html=True)
            
            st.markdown('<div class="sidebar-title">Chatbot FS-UEb âš¡</div>', unsafe_allow_html=True)
            st.markdown('<div class="sidebar-subtitle">UniversitÃ© d\'Ebolowa<br/>FacultÃ© des Sciences</div>', unsafe_allow_html=True)
            
            st.markdown("---")
            
            st.markdown("### ğŸš€ Optimisations Actives")
            optimizations = [
                "âœ… Cache intelligent des rÃ©ponses",
                "âœ… ModÃ¨le prÃ©chargÃ©",
                "âœ… Streaming fluide",
                "âœ… Interface rÃ©active",
            ]
            for opt in optimizations:
                st.markdown(f"<small>{opt}</small>", unsafe_allow_html=True)
            
            st.markdown("---")
            st.markdown("### â„¹ï¸ Informations")
            st.info("Ce chatbot est optimisÃ© pour rÃ©pondre rapidement aux questions basÃ©es sur les documents de la FacultÃ© des Sciences. Posez vos questions en toute simplicitÃ© !")
            
            st.markdown("---")
            st.markdown("### ğŸ”§ FonctionnalitÃ©s")
            st.markdown("""
            - ğŸ” Recherche vectorielle rapide
            - ğŸ¤– RÃ©ponse basÃ©e sur les documents contenant les informations sur la facultÃ©
            - ğŸ“š Cache intelligent
            - âš¡ RÃ©ponses en temps rÃ©el
            - ğŸ¯ Interface moderne
            """)
            
            if st.button("ğŸ—‘ï¸ Vider le cache"):
                self.chatbot_logic.cache_responses.clear()
                if hasattr(st.session_state, 'messages'):
                    st.session_state.messages = []
                st.success("Cache vidÃ© !")
                st.rerun()

    def render_performance_metrics(self):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                label="ğŸ“ RÃ©ponses en cache", 
                value=len(self.chatbot_logic.cache_responses),
                help="Nombre de rÃ©ponses mises en cache"
            )
        
        with col2:
            docs_loaded = len(getattr(st.session_state, 'texts', []))
            st.metric(
                label="ğŸ“š Documents chargÃ©s", 
                value=docs_loaded,
                help="Nombre de chunks de documents disponibles"
            )
        
        with col3:
            index_status = "âœ… Actif" if self.chatbot_logic.retriever else "âŒ Inactif"
            st.metric(
                label="ğŸ” Index FAISS", 
                value=index_status,
                help="Statut de l'index de recherche vectorielle"
            )

    def render_quick_questions(self):
        st.markdown("### ğŸ’¬ Questions rapides")
        
        quick_questions = [
            "Quels sont les programmes d'Ã©tudes disponibles ?",
            "Comment s'inscrire Ã  la facultÃ© ?",
            "Quels sont les frais de scolaritÃ© ?",
            "OÃ¹ trouve-t-on les emplois du temps ?"
        ]
        
        cols = st.columns(2)
        for i, question in enumerate(quick_questions):
            with cols[i % 2]:
                if st.button(f"â“ {question}", key=f"quick_{i}"):
                    st.session_state.messages.append({"role": "user", "content": question})
                    st.session_state.pending_query = question
                    st.rerun()

    def render_typing_animation(self, text, placeholder):
        displayed_text = ""
        for char in text:
            displayed_text += char
            placeholder.markdown(f"**{displayed_text}**")
            time.sleep(0.02)

    def process_query_streaming(self, user_query, status_placeholder, response_placeholder):
        full_response = ""
        current_status = ""
        
        try:
            for msg_type, content in self.chatbot_logic.run_query_with_status(user_query):
                if msg_type == "status":
                    current_status = content
                    status_placeholder.markdown(f"**{current_status}**")
                    
                elif msg_type == "content":
                    if current_status:
                        status_placeholder.empty()
                        current_status = ""
                    
                    full_response += content
                    response_placeholder.markdown(full_response + "â–Œ")
            
            status_placeholder.empty()
            response_placeholder.markdown(full_response)
            
            return full_response
            
        except Exception as e:
            status_placeholder.empty()
            error_msg = "âŒ Une erreur est survenue. Veuillez rÃ©essayer."
            response_placeholder.markdown(error_msg)
            return error_msg

    def render(self):
        st.set_page_config(
            page_title="Chatbot FS-UEb âš¡",
            layout="centered",
            initial_sidebar_state="collapsed"
        )
        
        load_custom_css()
        self.render_header()
        self.render_sidebar()
        
        with st.spinner("ğŸ“š Chargement des documents..."):
            self.chatbot_logic.prepare_data(st.session_state)
        
        with st.spinner("ğŸ” Initialisation de l'index..."):
            self.chatbot_logic.load_index(st.session_state)
        
        self.render_performance_metrics()
        st.markdown("---")
        
        st.markdown('<div class="fade-in">', unsafe_allow_html=True)
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
            welcome_msg = """
            ğŸ‘‹ Bonjour ! Je suis votre assistant intelligent optimisÃ© pour la FacultÃ© des Sciences.
            
            âš¡ **Nouvelles fonctionnalitÃ©s** :
            - Interface fluide et rÃ©active
            - Streaming en temps rÃ©el
            - Statuts de traitement visibles
            - RÃ©ponses plus naturelles
            
            Posez-moi vos questions sur les documents de la facultÃ© !
            """
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

        st.session_state.messages = st.session_state.messages[-15:]

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if len(st.session_state.messages) <= 1:
            self.render_quick_questions()
            st.markdown("---")

        if hasattr(st.session_state, 'pending_query'):
            user_query = st.session_state.pending_query
            delattr(st.session_state, 'pending_query')
            
            with st.chat_message("user"):
                st.markdown(user_query)
            
            with st.chat_message("assistant"):
                status_placeholder = st.empty()
                response_placeholder = st.empty()
                
                response = self.process_query_streaming(user_query, status_placeholder, response_placeholder)
                st.session_state.messages.append({"role": "assistant", "content": response})

        if user_query := st.chat_input("ğŸ’¬ Votre question (tapez puis EntrÃ©e)..."):
            with st.chat_message("user"):
                st.markdown(user_query)
            st.session_state.messages.append({"role": "user", "content": user_query})

            with st.chat_message("assistant"):
                status_placeholder = st.empty()
                response_placeholder = st.empty()
                
                response = self.process_query_streaming(user_query, status_placeholder, response_placeholder)
                st.session_state.messages.append({"role": "assistant", "content": response})
        
        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown("---")
        
        st.markdown("""
        <div style='text-align: center; color: #6b7280; font-size: 0.85rem; padding: 1rem;'>
            <p>âš¡ <strong>Chatbot FS-UEb OptimisÃ©</strong> - UniversitÃ© d'Ebolowa, FacultÃ© des Sciences</p>
            <p>ğŸš€ Esso Daniel - OPENMIND ACADEMY</p>
        </div>
        """, unsafe_allow_html=True)